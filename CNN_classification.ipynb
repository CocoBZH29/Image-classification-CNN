{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f932d0",
   "metadata": {},
   "source": [
    "# Projet image Classification CNN in PyTorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899dce5c",
   "metadata": {},
   "source": [
    "Le but de ce projet est de mettre en application les réseaux de neurones et la classification d'image. L'algorithme doit être capable de classifier une image dans l'une des dix catégories crées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0489d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08549675",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ #transforms.Compose permet de mettre plusieurs transformation au sein d'un même module\n",
    "    transforms.ToTensor(),       \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c931d774",
   "metadata": {},
   "source": [
    "transforms.Compose permet de mettre plusieurs transformation au sein d'un même module.\n",
    "\n",
    "transforms.ToTensor() permet de passer, pour une image, des valeurs [0;255] à [0;1] qui est plus standard pour les réseaux de neurones.\n",
    "\n",
    "transforms.Normalize permet de centrer les valeurs autours de 0 avec un écart-type de 0.5 soit [-1;1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f78604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [01:02<00:00, 2745636.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f5cf3",
   "metadata": {},
   "source": [
    "on télécharge deux datasets, un pour le train et un pour le test. Ils sont composés de 10 classes d'images (50 000 images de train et 10 000 de test) et on leur applique le transform.\n",
    "Le DataLoader permet de créer des lots de 32 images pour les traiter en parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b16438",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec0c535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b872715",
   "metadata": {},
   "source": [
    "Le 3 représente le RGB et 32x32 est la taille de l'image en pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4642862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'frog', 'horse', 'ship', 'truck'] #c'est les 10 classes d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32bd779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module): #on définit une classe NeuralNet qui hérite de nn.Module\n",
    "    \n",
    "    def __init__(self): #cst, on définit les couches de notre réseaux de neurones\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 12, 5) #3 est le nombre de feautures de notre image, 12 est le nombre de features map créées \n",
    "                                         #en sortie et 5 est la taille du kernel appliqué 5x5. Soit (12, 28, 28)\n",
    "        self.pool = nn.MaxPool2d(2, 2) #extrait le max d'un carré de 2x2 pixels d'où (12, 14, 14)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5) #Soit (24, 10, 10) -> (24, 5, 5) le pool est réappliqué -> Flatten (24*5*5)\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120) #dense layer, fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10) #il est obligatoire d'avoir 10 en outputs -> 10 classes d'images\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) #F.relu renvoit 0 si x<=0 et x si x>0 -> permet de casser la linéarité, améliore la capacité d'apprentissage\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1174250b",
   "metadata": {},
   "source": [
    "On a une nouvelle taille d'image: taille de l'image - taille du kernel -> 32-5=27\n",
    "\n",
    "nouvelle taille / pas de déplacement du kernel -> 27/1 = 27\n",
    "\n",
    "on ajoute 1 -> 27+1 = 28\n",
    "\n",
    "Une couche entièrement connectée : Chaque neurone reçoit des entrées de tous les neurones de la couche précédente. Cela signifie que chaque neurone de la couche suivante utilise des informations de tous les neurones de la couche précédente pour calculer sa sortie. il y a un poids et un biais qui permet de faire une transformation linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa914c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)#Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d380e3",
   "metadata": {},
   "source": [
    "La perte d'entropie croisée mesure la différence entre les probabilités prédites par le modèle et les véritables étiquettes de classe.\n",
    "\n",
    "SGD permet de mettre à jour les paramètres de net pendant l'apprentissage. lr = learning rate, c'est la taille de mise à jour de poids à chaque itérations. momentum : aide à accélérer l'optimisation en tenant compte des mises à jour passées. Le momentum permet de \"lisser\" les mises à jour et d'aider à surmonter les petits minima locaux dans le paysage de perte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef54dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "loss: 2.2159\n",
      "Training epoch 1...\n",
      "loss: 1.7511\n",
      "Training epoch 2...\n",
      "loss: 1.5272\n",
      "Training epoch 3...\n",
      "loss: 1.4038\n",
      "Training epoch 4...\n",
      "loss: 1.3004\n",
      "Training epoch 5...\n",
      "loss: 1.2113\n",
      "Training epoch 6...\n",
      "loss: 1.1377\n",
      "Training epoch 7...\n",
      "loss: 1.0800\n",
      "Training epoch 8...\n",
      "loss: 1.0228\n",
      "Training epoch 9...\n",
      "loss: 0.9789\n",
      "Training epoch 10...\n",
      "loss: 0.9407\n",
      "Training epoch 11...\n",
      "loss: 0.8958\n",
      "Training epoch 12...\n",
      "loss: 0.8641\n",
      "Training epoch 13...\n",
      "loss: 0.8281\n",
      "Training epoch 14...\n",
      "loss: 0.7978\n",
      "Training epoch 15...\n",
      "loss: 0.7653\n",
      "Training epoch 16...\n",
      "loss: 0.7330\n",
      "Training epoch 17...\n",
      "loss: 0.7064\n",
      "Training epoch 18...\n",
      "loss: 0.6807\n",
      "Training epoch 19...\n",
      "loss: 0.6517\n",
      "Training epoch 20...\n",
      "loss: 0.6289\n",
      "Training epoch 21...\n",
      "loss: 0.6013\n",
      "Training epoch 22...\n",
      "loss: 0.5813\n",
      "Training epoch 23...\n",
      "loss: 0.5561\n",
      "Training epoch 24...\n",
      "loss: 0.5369\n",
      "Training epoch 25...\n",
      "loss: 0.5154\n",
      "Training epoch 26...\n",
      "loss: 0.4952\n",
      "Training epoch 27...\n",
      "loss: 0.4723\n",
      "Training epoch 28...\n",
      "loss: 0.4501\n",
      "Training epoch 29...\n",
      "loss: 0.4349\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch {epoch}...')#epoch ou époque représente un passage entier dans le NN\n",
    "    \n",
    "    running_loss = 0.0 \n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data #on sépare data en 2, l'image et son label\n",
    "        \n",
    "        optimizer.zero_grad() #PyTorch accumule les gradients par défaut, on les réinitialise pour pas qu'il y est d'influence\n",
    "        \n",
    "        outputs = net(inputs) #au début des ité, les outputs seront aléatoires puis vont s'améliorer à chaque ité\n",
    "        \n",
    "        loss = loss_function(outputs, labels)#on va chercher la perte entre la prédiction et le res attendu\n",
    "        loss.backward() #Calcule les gradients pour tous les paramètres du modèle en fonction de la perte.\n",
    "        optimizer.step() #Met à jour les poids du modèle en utilisant les gradients calculés et le taux d'apprentissage défini dans l'optimiseur.\n",
    "        \n",
    "        running_loss += loss.item() #.item convertit le tensor de la perte en float\n",
    "        \n",
    "    print(f'loss: {running_loss/len(train_loader):.4f}') #perte moyenne par lot avec 4 chiffres après la virgule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a947303",
   "metadata": {},
   "source": [
    "On veut voir une convergence des epoch aux alentours de 0.3 ou 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b516ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth') #on sauvegarde l'état des poids du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257ec0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62efc371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.15%\n"
     ]
    }
   ],
   "source": [
    "correct = 0 #compte le nombre de prédictions correctes faites par le modèle.\n",
    "total = 0 #compte le nombre total d'exemples dans l'ensemble de test.\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad(): #on ne calcule pas les gradients, pas nécessaire pour l'évaluation, donc permet d'économiser du tps de calcul\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1) #trouve l'indice de la classe avec la plus haute probabilité dans les sorties du modèle.\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b624f",
   "metadata": {},
   "source": [
    "### On test le modèle sur 2 exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc8482de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ship\n",
      "Prediction: truck\n",
      "Prediction: cat\n",
      "Prediction: cat\n",
      "Prediction: horse\n",
      "Prediction: frog\n",
      "Prediction: truck\n",
      "Prediction: deer\n"
     ]
    }
   ],
   "source": [
    "new_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),       \n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = new_transform(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_paths = ['C:/Users/coren/Documents/PERSO/COURS_PERSO/bateau.jpg', \n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/camion.jpg', \n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/chevreuil.jpg', \n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/chat.jpg', \n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/cheval.jpg',\n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/grenouille.jpg',\n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/casserole.jpg',\n",
    "               'C:/Users/coren/Documents/PERSO/COURS_PERSO/macron.jpg']\n",
    "images = [load_image(img) for img in image_paths]\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        output = net(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        print(f'Prediction: {class_names[predicted.item()-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6e2629",
   "metadata": {},
   "source": [
    "On voit que l'algorithme a du mal a différencié le chevreuil du chat, mais sinon les résultats sont bons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc25570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
